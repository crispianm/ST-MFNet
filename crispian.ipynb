{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3090'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from models import *\n",
    "from data import testsets\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from data.datasets import *\n",
    "from trainers.distiller import Distiller\n",
    "from torch.utils.data import DataLoader\n",
    "import models\n",
    "import losses\n",
    "import datetime\n",
    "from os.path import join\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class testArgs:\n",
    "    gpu_id = 0\n",
    "    net = 'STMFNet'\n",
    "    dataset = 'Ucf101_quintuplet'\n",
    "    metrics = ['PSNR', 'SSIM']\n",
    "    checkpoint = './models/stmfnet.pth'\n",
    "    data_dir = 'D:/stmfnet_data'\n",
    "    out_dir = './tests'\n",
    "    featc = [64, 128, 256, 512]\n",
    "    featnet = 'UMultiScaleResNext'\n",
    "    featnorm = 'batch'\n",
    "    kernel_size = 5\n",
    "    dilation = 1\n",
    "    finetune_pwc = False\n",
    "\n",
    "class trainArgs:\n",
    "    gpu_id = 0\n",
    "    net = 'STMFNet'\n",
    "    data_dir = 'D:/stmfnet_data'\n",
    "    out_dir = './train_results'\n",
    "    load = None\n",
    "    epochs = 70\n",
    "    batch_size = 2\n",
    "    loss = \"1*Lap\"\n",
    "    patch_size = 256\n",
    "    lr = 0.001\n",
    "    lr_decay = 20\n",
    "    decay_type = 'step'\n",
    "    gamma = 0.5\n",
    "    patience = None\n",
    "    optimizer = 'ADAMax'\n",
    "    weight_decay = 0\n",
    "    featc = [64, 128, 256, 512]\n",
    "    featnet = 'UMultiScaleResNext'\n",
    "    featnorm = 'batch'\n",
    "    kernel_size = 5\n",
    "    dilation = 1\n",
    "    finetune_pwc = False\n",
    "\n",
    "args=trainArgs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(args.gpu_id)\n",
    "\n",
    "# training sets\n",
    "vimeo90k_train = Vimeo90k_quintuplet(\n",
    "    join(args.data_dir, \"vimeo_septuplet\"),\n",
    "    train=True,\n",
    "    crop_sz=(args.patch_size, args.patch_size),\n",
    ")\n",
    "bvidvc_train = BVIDVC_quintuplet(\n",
    "    join(args.data_dir, \"bvidvc\"), crop_sz=(args.patch_size, args.patch_size)\n",
    ")\n",
    "\n",
    "# validation set\n",
    "vimeo90k_valid = Vimeo90k_quintuplet(\n",
    "    join(args.data_dir, \"vimeo_septuplet\"),\n",
    "    train=False,\n",
    "    crop_sz=(args.patch_size, args.patch_size),\n",
    "    augment_s=False,\n",
    "    augment_t=False,\n",
    ")\n",
    "\n",
    "datasets_train = [vimeo90k_train, bvidvc_train]\n",
    "train_sampler = Sampler(datasets_train, iter=True)\n",
    "\n",
    "# data loaders\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_sampler, batch_size=args.batch_size, shuffle=True, num_workers=0\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    dataset=vimeo90k_valid, batch_size=args.batch_size, num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### teacher model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "\n",
    "torch.cuda.set_device(args.gpu_id)\n",
    "\n",
    "if not os.path.exists(args.out_dir):\n",
    "    os.mkdir(args.out_dir)\n",
    "\n",
    "def to_device(data, device):\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "# def load_model(filepath):\n",
    "\n",
    "#     checkpoint = torch.load(filepath)\n",
    "#     model = STMFNet(args).cuda()\n",
    "#     model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# model = load_model(\"./models/stmfnet.pth\")\n",
    "\n",
    "teacher = to_device(STMFNet(args), device)\n",
    "teacher.to(device)\n",
    "checkpoint = torch.load('./models/stmfnet.pth')\n",
    "teacher.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### student model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from models.misc.resnet_3D import r3d_18, Conv_3d, upConv3D\n",
    "from models.misc import Identity\n",
    "import cupy_module.adacof as adacof\n",
    "from cupy_module.softsplat import ModuleSoftsplat\n",
    "import sys\n",
    "from torch.nn import functional as F\n",
    "from utility import moduleNormalize, gaussian_kernel\n",
    "from models import feature\n",
    "from models.misc import MIMOGridNet, Upsampler_8tap\n",
    "from models.misc import PWCNet\n",
    "from models.misc.pwcnet import backwarp\n",
    "\n",
    "class UNet3d_18(nn.Module):\n",
    "    def __init__(self, channels=[32, 64, 96, 128], bn=True):\n",
    "        super(UNet3d_18, self).__init__()\n",
    "        growth = 2  # since concatenating previous outputs\n",
    "        upmode = \"transpose\"  # use transposeConv to upsample\n",
    "\n",
    "        self.channels = channels\n",
    "\n",
    "        self.lrelu = nn.LeakyReLU(0.2, True)\n",
    "\n",
    "        self.encoder = r3d_18(bn=bn, channels=channels)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            Conv_3d(\n",
    "                channels[::-1][0],\n",
    "                channels[::-1][1],\n",
    "                kernel_size=3,\n",
    "                padding=1,\n",
    "                bias=True,\n",
    "            ),\n",
    "            upConv3D(\n",
    "                channels[::-1][1] * growth,\n",
    "                channels[::-1][2],\n",
    "                kernel_size=(3, 4, 4),\n",
    "                stride=(1, 2, 2),\n",
    "                padding=(1, 1, 1),\n",
    "                upmode=upmode,\n",
    "            ),\n",
    "            upConv3D(\n",
    "                channels[::-1][2] * growth,\n",
    "                channels[::-1][3],\n",
    "                kernel_size=(3, 4, 4),\n",
    "                stride=(1, 2, 2),\n",
    "                padding=(1, 1, 1),\n",
    "                upmode=upmode,\n",
    "            ),\n",
    "            Conv_3d(\n",
    "                channels[::-1][3] * growth,\n",
    "                channels[::-1][3],\n",
    "                kernel_size=3,\n",
    "                padding=1,\n",
    "                bias=True,\n",
    "            ),\n",
    "            upConv3D(\n",
    "                channels[::-1][3] * growth,\n",
    "                channels[::-1][3],\n",
    "                kernel_size=(3, 4, 4),\n",
    "                stride=(1, 2, 2),\n",
    "                padding=(1, 1, 1),\n",
    "                upmode=upmode,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        self.feature_fuse = nn.Sequential(\n",
    "            *(\n",
    "                [\n",
    "                    nn.Conv2d(\n",
    "                        channels[::-1][3] * 5,\n",
    "                        channels[::-1][3],\n",
    "                        kernel_size=1,\n",
    "                        stride=1,\n",
    "                        bias=False,\n",
    "                    )\n",
    "                ]\n",
    "                + [nn.BatchNorm2d(channels[::-1][3]) if bn else Identity]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.outconv = nn.Sequential(\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(channels[::-1][3], 3, kernel_size=7, stride=1, padding=0),\n",
    "        )\n",
    "\n",
    "    def forward(self, im1, im3, im5, im7, im4_tilde):\n",
    "        images = torch.stack((im1, im3, im4_tilde, im5, im7), dim=2)\n",
    "\n",
    "        x_0, x_1, x_2, x_3, x_4 = self.encoder(images)\n",
    "\n",
    "        dx_3 = self.lrelu(self.decoder[0](x_4))\n",
    "        dx_3 = torch.cat([dx_3, x_3], dim=1)\n",
    "\n",
    "        dx_2 = self.lrelu(self.decoder[1](dx_3))\n",
    "        dx_2 = torch.cat([dx_2, x_2], dim=1)\n",
    "\n",
    "        dx_1 = self.lrelu(self.decoder[2](dx_2))\n",
    "        dx_1 = torch.cat([dx_1, x_1], dim=1)\n",
    "\n",
    "        dx_0 = self.lrelu(self.decoder[3](dx_1))\n",
    "        dx_0 = torch.cat([dx_0, x_0], dim=1)\n",
    "\n",
    "        dx_out = self.lrelu(self.decoder[4](dx_0))\n",
    "        dx_out = torch.cat(torch.unbind(dx_out, 2), 1)\n",
    "\n",
    "        out = self.lrelu(self.feature_fuse(dx_out))\n",
    "        out = self.outconv(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class KernelEstimation(torch.nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super(KernelEstimation, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        def Subnet_offset(ks):\n",
    "            return torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(\n",
    "                    in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1\n",
    "                ),\n",
    "                torch.nn.ReLU(inplace=False),\n",
    "                torch.nn.Conv2d(\n",
    "                    in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1\n",
    "                ),\n",
    "                torch.nn.ReLU(inplace=False),\n",
    "                torch.nn.Conv2d(\n",
    "                    in_channels=64, out_channels=ks, kernel_size=3, stride=1, padding=1\n",
    "                ),\n",
    "                torch.nn.ReLU(inplace=False),\n",
    "                torch.nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True),\n",
    "                torch.nn.Conv2d(\n",
    "                    in_channels=ks, out_channels=ks, kernel_size=3, stride=1, padding=1\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        def Subnet_weight(ks):\n",
    "            return torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(\n",
    "                    in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1\n",
    "                ),\n",
    "                torch.nn.ReLU(inplace=False),\n",
    "                torch.nn.Conv2d(\n",
    "                    in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1\n",
    "                ),\n",
    "                torch.nn.ReLU(inplace=False),\n",
    "                torch.nn.Conv2d(\n",
    "                    in_channels=64, out_channels=ks, kernel_size=3, stride=1, padding=1\n",
    "                ),\n",
    "                torch.nn.ReLU(inplace=False),\n",
    "                torch.nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True),\n",
    "                torch.nn.Conv2d(\n",
    "                    in_channels=ks, out_channels=ks, kernel_size=3, stride=1, padding=1\n",
    "                ),\n",
    "                torch.nn.Softmax(dim=1),\n",
    "            )\n",
    "\n",
    "        def Subnet_offset_ds(ks):\n",
    "            return torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(\n",
    "                    in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1\n",
    "                ),\n",
    "                torch.nn.ReLU(inplace=False),\n",
    "                torch.nn.Conv2d(\n",
    "                    in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1\n",
    "                ),\n",
    "                torch.nn.ReLU(inplace=False),\n",
    "                torch.nn.Conv2d(\n",
    "                    in_channels=64, out_channels=ks, kernel_size=3, stride=1, padding=1\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        def Subnet_weight_ds(ks):\n",
    "            return torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(\n",
    "                    in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1\n",
    "                ),\n",
    "                torch.nn.ReLU(inplace=False),\n",
    "                torch.nn.Conv2d(\n",
    "                    in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1\n",
    "                ),\n",
    "                torch.nn.ReLU(inplace=False),\n",
    "                torch.nn.Conv2d(\n",
    "                    in_channels=64, out_channels=ks, kernel_size=3, stride=1, padding=1\n",
    "                ),\n",
    "                torch.nn.Softmax(dim=1),\n",
    "            )\n",
    "\n",
    "        def Subnet_offset_us(ks):\n",
    "            return torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(\n",
    "                    in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1\n",
    "                ),\n",
    "                torch.nn.ReLU(inplace=False),\n",
    "                torch.nn.Conv2d(\n",
    "                    in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1\n",
    "                ),\n",
    "                torch.nn.ReLU(inplace=False),\n",
    "                torch.nn.Conv2d(\n",
    "                    in_channels=64, out_channels=ks, kernel_size=3, stride=1, padding=1\n",
    "                ),\n",
    "                torch.nn.ReLU(inplace=False),\n",
    "                torch.nn.Upsample(scale_factor=4, mode=\"bilinear\", align_corners=True),\n",
    "                torch.nn.Conv2d(\n",
    "                    in_channels=ks, out_channels=ks, kernel_size=3, stride=1, padding=1\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        def Subnet_weight_us(ks):\n",
    "            return torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(\n",
    "                    in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1\n",
    "                ),\n",
    "                torch.nn.ReLU(inplace=False),\n",
    "                torch.nn.Conv2d(\n",
    "                    in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1\n",
    "                ),\n",
    "                torch.nn.ReLU(inplace=False),\n",
    "                torch.nn.Conv2d(\n",
    "                    in_channels=64, out_channels=ks, kernel_size=3, stride=1, padding=1\n",
    "                ),\n",
    "                torch.nn.ReLU(inplace=False),\n",
    "                torch.nn.Upsample(scale_factor=4, mode=\"bilinear\", align_corners=True),\n",
    "                torch.nn.Conv2d(\n",
    "                    in_channels=ks, out_channels=ks, kernel_size=3, stride=1, padding=1\n",
    "                ),\n",
    "                torch.nn.Softmax(dim=1),\n",
    "            )\n",
    "\n",
    "        self.moduleWeight1_ds = Subnet_weight_ds(self.kernel_size**2)\n",
    "        self.moduleAlpha1_ds = Subnet_offset_ds(self.kernel_size**2)\n",
    "        self.moduleBeta1_ds = Subnet_offset_ds(self.kernel_size**2)\n",
    "        self.moduleWeight2_ds = Subnet_weight_ds(self.kernel_size**2)\n",
    "        self.moduleAlpha2_ds = Subnet_offset_ds(self.kernel_size**2)\n",
    "        self.moduleBeta2_ds = Subnet_offset_ds(self.kernel_size**2)\n",
    "\n",
    "        self.moduleWeight1 = Subnet_weight(self.kernel_size**2)\n",
    "        self.moduleAlpha1 = Subnet_offset(self.kernel_size**2)\n",
    "        self.moduleBeta1 = Subnet_offset(self.kernel_size**2)\n",
    "        self.moduleWeight2 = Subnet_weight(self.kernel_size**2)\n",
    "        self.moduleAlpha2 = Subnet_offset(self.kernel_size**2)\n",
    "        self.moduleBeta2 = Subnet_offset(self.kernel_size**2)\n",
    "\n",
    "        self.moduleWeight1_us = Subnet_weight_us(self.kernel_size**2)\n",
    "        self.moduleAlpha1_us = Subnet_offset_us(self.kernel_size**2)\n",
    "        self.moduleBeta1_us = Subnet_offset_us(self.kernel_size**2)\n",
    "        self.moduleWeight2_us = Subnet_weight_us(self.kernel_size**2)\n",
    "        self.moduleAlpha2_us = Subnet_offset_us(self.kernel_size**2)\n",
    "        self.moduleBeta2_us = Subnet_offset_us(self.kernel_size**2)\n",
    "\n",
    "    def forward(self, tensorCombine):\n",
    "        # Frame 0\n",
    "        Weight1_ds = self.moduleWeight1_ds(tensorCombine)\n",
    "        Weight1 = self.moduleWeight1(tensorCombine)\n",
    "        Weight1_us = self.moduleWeight1_us(tensorCombine)\n",
    "        Alpha1_ds = self.moduleAlpha1_ds(tensorCombine)\n",
    "        Alpha1 = self.moduleAlpha1(tensorCombine)\n",
    "        Alpha1_us = self.moduleAlpha1_us(tensorCombine)\n",
    "        Beta1_ds = self.moduleBeta1_ds(tensorCombine)\n",
    "        Beta1 = self.moduleBeta1(tensorCombine)\n",
    "        Beta1_us = self.moduleBeta1_us(tensorCombine)\n",
    "\n",
    "        # Frame 2\n",
    "        Weight2_ds = self.moduleWeight2_ds(tensorCombine)\n",
    "        Weight2 = self.moduleWeight2(tensorCombine)\n",
    "        Weight2_us = self.moduleWeight2_us(tensorCombine)\n",
    "        Alpha2_ds = self.moduleAlpha2_ds(tensorCombine)\n",
    "        Alpha2 = self.moduleAlpha2(tensorCombine)\n",
    "        Alpha2_us = self.moduleAlpha2_us(tensorCombine)\n",
    "        Beta2_ds = self.moduleBeta2_ds(tensorCombine)\n",
    "        Beta2 = self.moduleBeta2(tensorCombine)\n",
    "        Beta2_us = self.moduleBeta2_us(tensorCombine)\n",
    "\n",
    "        return (\n",
    "            Weight1_ds,\n",
    "            Alpha1_ds,\n",
    "            Beta1_ds,\n",
    "            Weight2_ds,\n",
    "            Alpha2_ds,\n",
    "            Beta2_ds,\n",
    "            Weight1,\n",
    "            Alpha1,\n",
    "            Beta1,\n",
    "            Weight2,\n",
    "            Alpha2,\n",
    "            Beta2,\n",
    "            Weight1_us,\n",
    "            Alpha1_us,\n",
    "            Beta1_us,\n",
    "            Weight2_us,\n",
    "            Alpha2_us,\n",
    "            Beta2_us,\n",
    "        )\n",
    "\n",
    "\n",
    "class student_STMFNet(torch.nn.Module):\n",
    "    def __init__(self, args):\n",
    "\n",
    "        super(student_STMFNet, self).__init__()\n",
    "\n",
    "        class Metric(torch.nn.Module):\n",
    "            def __init__(self):\n",
    "                super(Metric, self).__init__()\n",
    "                self.paramScale = torch.nn.Parameter(-torch.ones(1, 1, 1, 1))\n",
    "\n",
    "            def forward(self, tenFirst, tenSecond, tenFlow):\n",
    "                return self.paramScale * F.l1_loss(\n",
    "                    input=tenFirst,\n",
    "                    target=backwarp(tenSecond, tenFlow),\n",
    "                    reduction=\"none\",\n",
    "                ).mean(1, True)\n",
    "\n",
    "        self.args = args\n",
    "        self.kernel_size = args.kernel_size\n",
    "        self.kernel_pad = int(((args.kernel_size - 1) * args.dilation) / 2.0)\n",
    "        self.dilation = args.dilation\n",
    "\n",
    "        self.feature_extractor = getattr(feature, args.featnet)(\n",
    "            args.featc, norm_layer=args.featnorm\n",
    "        )\n",
    "\n",
    "        self.get_kernel = KernelEstimation(self.kernel_size)\n",
    "\n",
    "        self.modulePad = torch.nn.ReplicationPad2d(\n",
    "            [self.kernel_pad, self.kernel_pad, self.kernel_pad, self.kernel_pad]\n",
    "        )\n",
    "\n",
    "        self.moduleAdaCoF = adacof.FunctionAdaCoF.apply\n",
    "\n",
    "        self.gauss_kernel = torch.nn.Parameter(\n",
    "            gaussian_kernel(5, 0.5).repeat(3, 1, 1, 1), requires_grad=False\n",
    "        )\n",
    "\n",
    "        self.upsampler = Upsampler_8tap()\n",
    "\n",
    "        self.scale_synthesis = MIMOGridNet(\n",
    "            (6, 6 + 6, 6), (3,), grid_chs=(32, 64, 96), n_row=3, n_col=4, outrow=(1,)\n",
    "        )\n",
    "\n",
    "        self.flow_estimator = PWCNet()\n",
    "\n",
    "        self.softsplat = ModuleSoftsplat(strType=\"softmax\")\n",
    "\n",
    "        self.metric = Metric()\n",
    "\n",
    "        self.dyntex_generator = UNet3d_18(bn=args.featnorm)\n",
    "\n",
    "        # freeze weights of PWCNet if not finetuning it\n",
    "        if not args.finetune_pwc:\n",
    "            for param in self.flow_estimator.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, I0, I1, I2, I3, *args):\n",
    "        h0 = int(list(I1.size())[2])\n",
    "        w0 = int(list(I1.size())[3])\n",
    "        h2 = int(list(I2.size())[2])\n",
    "        w2 = int(list(I2.size())[3])\n",
    "        if h0 != h2 or w0 != w2:\n",
    "            sys.exit(\"Frame sizes do not match\")\n",
    "\n",
    "        h_padded = False\n",
    "        w_padded = False\n",
    "        if h0 % 128 != 0:\n",
    "            pad_h = 128 - (h0 % 128)\n",
    "            I0 = F.pad(I0, (0, 0, 0, pad_h), mode=\"reflect\")\n",
    "            I1 = F.pad(I1, (0, 0, 0, pad_h), mode=\"reflect\")\n",
    "            I2 = F.pad(I2, (0, 0, 0, pad_h), mode=\"reflect\")\n",
    "            I3 = F.pad(I3, (0, 0, 0, pad_h), mode=\"reflect\")\n",
    "            h_padded = True\n",
    "\n",
    "        if w0 % 128 != 0:\n",
    "            pad_w = 128 - (w0 % 128)\n",
    "            I0 = F.pad(I0, (0, pad_w, 0, 0), mode=\"reflect\")\n",
    "            I1 = F.pad(I1, (0, pad_w, 0, 0), mode=\"reflect\")\n",
    "            I2 = F.pad(I2, (0, pad_w, 0, 0), mode=\"reflect\")\n",
    "            I3 = F.pad(I3, (0, pad_w, 0, 0), mode=\"reflect\")\n",
    "            w_padded = True\n",
    "\n",
    "        feats = self.feature_extractor(moduleNormalize(I1), moduleNormalize(I2))\n",
    "        kernelest = self.get_kernel(feats)\n",
    "        Weight1_ds, Alpha1_ds, Beta1_ds, Weight2_ds, Alpha2_ds, Beta2_ds = kernelest[:6]\n",
    "        Weight1, Alpha1, Beta1, Weight2, Alpha2, Beta2 = kernelest[6:12]\n",
    "        Weight1_us, Alpha1_us, Beta1_us, Weight2_us, Alpha2_us, Beta2_us = kernelest[\n",
    "            12:\n",
    "        ]\n",
    "\n",
    "        # Original scale\n",
    "        tensorAdaCoF1 = (\n",
    "            self.moduleAdaCoF(self.modulePad(I1), Weight1, Alpha1, Beta1, self.dilation)\n",
    "            * 1.0\n",
    "        )\n",
    "        tensorAdaCoF2 = (\n",
    "            self.moduleAdaCoF(self.modulePad(I2), Weight2, Alpha2, Beta2, self.dilation)\n",
    "            * 1.0\n",
    "        )\n",
    "\n",
    "        # 1/2 downsampled version\n",
    "        c, h, w = I1.shape[1:]\n",
    "        p = (self.gauss_kernel.shape[-1] - 1) // 2\n",
    "        I1_blur = F.conv2d(\n",
    "            F.pad(I1, pad=(p, p, p, p), mode=\"reflect\"), self.gauss_kernel, groups=c\n",
    "        )\n",
    "        I2_blur = F.conv2d(\n",
    "            F.pad(I2, pad=(p, p, p, p), mode=\"reflect\"), self.gauss_kernel, groups=c\n",
    "        )\n",
    "        I1_ds = F.interpolate(\n",
    "            I1_blur, size=(h // 2, w // 2), mode=\"bilinear\", align_corners=False\n",
    "        )\n",
    "        I2_ds = F.interpolate(\n",
    "            I2_blur, size=(h // 2, w // 2), mode=\"bilinear\", align_corners=False\n",
    "        )\n",
    "        tensorAdaCoF1_ds = (\n",
    "            self.moduleAdaCoF(\n",
    "                self.modulePad(I1_ds), Weight1_ds, Alpha1_ds, Beta1_ds, self.dilation\n",
    "            )\n",
    "            * 1.0\n",
    "        )\n",
    "        tensorAdaCoF2_ds = (\n",
    "            self.moduleAdaCoF(\n",
    "                self.modulePad(I2_ds), Weight2_ds, Alpha2_ds, Beta2_ds, self.dilation\n",
    "            )\n",
    "            * 1.0\n",
    "        )\n",
    "\n",
    "        # x2 upsampled version\n",
    "        I1_us = self.upsampler(I1)\n",
    "        I2_us = self.upsampler(I2)\n",
    "        tensorAdaCoF1_us = (\n",
    "            self.moduleAdaCoF(\n",
    "                self.modulePad(I1_us), Weight1_us, Alpha1_us, Beta1_us, self.dilation\n",
    "            )\n",
    "            * 1.0\n",
    "        )\n",
    "        tensorAdaCoF2_us = (\n",
    "            self.moduleAdaCoF(\n",
    "                self.modulePad(I2_us), Weight2_us, Alpha2_us, Beta2_us, self.dilation\n",
    "            )\n",
    "            * 1.0\n",
    "        )\n",
    "\n",
    "        # use softsplat for refinement\n",
    "        pyramid0, pyramid2 = self.flow_estimator.extract_pyramid(I1, I2)\n",
    "        flow_0_2 = 20 * self.flow_estimator(I1, I2, pyramid0, pyramid2)\n",
    "        flow_0_2 = F.interpolate(\n",
    "            flow_0_2, size=(h, w), mode=\"bilinear\", align_corners=False\n",
    "        )\n",
    "        flow_2_0 = 20 * self.flow_estimator(I2, I1, pyramid2, pyramid0)\n",
    "        flow_2_0 = F.interpolate(\n",
    "            flow_2_0, size=(h, w), mode=\"bilinear\", align_corners=False\n",
    "        )\n",
    "        metric_0_2 = self.metric(I1, I2, flow_0_2)\n",
    "        metric_2_0 = self.metric(I2, I1, flow_2_0)\n",
    "        tensorSoftsplat0 = self.softsplat(I1, 0.5 * flow_0_2, metric_0_2)\n",
    "        tensorSoftsplat2 = self.softsplat(I2, 0.5 * flow_2_0, metric_2_0)\n",
    "\n",
    "        # synthesize multiple scales\n",
    "        tensorCombine_us = torch.cat([tensorAdaCoF1_us, tensorAdaCoF2_us], dim=1)\n",
    "        tensorCombine = torch.cat(\n",
    "            [tensorAdaCoF1, tensorAdaCoF2, tensorSoftsplat0, tensorSoftsplat2], dim=1\n",
    "        )\n",
    "        tensorCombine_ds = torch.cat([tensorAdaCoF1_ds, tensorAdaCoF2_ds], dim=1)\n",
    "        output_tilde = self.scale_synthesis(\n",
    "            tensorCombine_us, tensorCombine, tensorCombine_ds\n",
    "        )[0]\n",
    "\n",
    "        # generate dynamic texture\n",
    "        dyntex = self.dyntex_generator(I0, I1, I2, I3, output_tilde)\n",
    "        output = output_tilde + dyntex\n",
    "\n",
    "        if h_padded:\n",
    "            output = output[:, :, 0:h0, :]\n",
    "        if w_padded:\n",
    "            output = output[:, :, :, 0:w0]\n",
    "\n",
    "        if self.training:\n",
    "            return {\"frame1\": output}\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "\n",
    "student = student_STMFNet(args)\n",
    "student.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distillation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 3 required positional arguments: 'I1', 'I2', and 'I3'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7776\\2129853972.py\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m                 \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mteacher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m                 \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstudent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmy_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemperature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\wg19671\\Anaconda3\\envs\\stmfnet\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: forward() missing 3 required positional arguments: 'I1', 'I2', and 'I3'"
     ]
    }
   ],
   "source": [
    "args=trainArgs()\n",
    "\n",
    "softmax_optimiser = nn.Softmax(dim=1)\n",
    "mse_loss_function = nn.MSELoss()\n",
    "\n",
    "def my_loss(scores, targets, temperature = 5):\n",
    "    soft_pred = softmax_optimiser(scores / temperature)\n",
    "    soft_targets = softmax_optimiser(targets / temperature)\n",
    "    loss = mse_loss_function(soft_pred, soft_targets)\n",
    "    return loss\n",
    "\n",
    "distil_optimizer = optim.Adam(student.parameters(), lr=0.0001)\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(5):\n",
    "\n",
    "\trunning_loss = 0.0\n",
    "\tfor i, data in enumerate(train_loader, 1):\n",
    "\n",
    "\t\tinputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "\t\ttargets = teacher(inputs)\n",
    "\t\tscores = student(inputs)\n",
    "\t\tloss = my_loss(scores, targets, temperature = 2)\n",
    "\t\tdistil_optimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\tdistil_optimizer.step()\n",
    "\n",
    "\t\t# print statistics\n",
    "\t\trunning_loss += loss.item()\n",
    "\t\tif i % 60 == 59:    # print every 60 mini-batches\n",
    "\t\t\tprint(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 60:.3f}')\n",
    "\t\t\trunning_loss = 0.0\n",
    "\t\t\n",
    "\tprint('appending loss: ', loss.item())\n",
    "\tlosses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.000 * Lap\n",
      "loss  1 :  tensor(116355.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss  2 :  tensor(209200.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss  3 :  tensor(106750.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss  4 :  tensor(77347.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss  5 :  tensor(49366.7305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss  6 :  tensor(36558.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss  7 :  tensor(28091.4160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss  8 :  tensor(27802.7461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss  9 :  tensor(39013.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss  10 :  tensor(31195.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss  11 :  tensor(23082.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss  12 :  tensor(28373.3301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss  13 :  tensor(26240.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss  14 :  tensor(22674.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss  15 :  tensor(19716.9395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss  16 :  tensor(20322.2617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss  17 :  tensor(27337.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss  18 :  tensor(27049.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss  19 :  tensor(20514.7930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss  20 :  tensor(20609.7930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss  21 :  tensor(20230.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss  22 :  tensor(15321.4854, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss  23 :  tensor(19455.8887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss  24 :  tensor(17794.0566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss  25 :  tensor(15774.0654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss  26 :  tensor(17258.3105, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7776\\3611817552.py\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmy_trainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mmy_trainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mmy_trainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mmy_trainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\wg19671\\Desktop\\ST-MFNet\\trainers\\distiller.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mpsnr_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         for batch_idx, (frame1, frame3, frame4, frame5, frame7) in enumerate(\n\u001b[0m\u001b[0;32m     46\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         ):\n",
      "\u001b[1;32mc:\\Users\\wg19671\\Anaconda3\\envs\\stmfnet\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\wg19671\\Anaconda3\\envs\\stmfnet\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    568\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\wg19671\\Anaconda3\\envs\\stmfnet\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\wg19671\\Anaconda3\\envs\\stmfnet\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\wg19671\\Desktop\\ST-MFNet\\data\\datasets.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccum\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccum\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;31m# first sample a dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\wg19671\\Desktop\\ST-MFNet\\data\\datasets.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mrawFrame1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq_path_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"im1.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mrawFrame3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq_path_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"im3.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mrawFrame4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq_path_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"im4.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mrawFrame5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq_path_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"im5.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\wg19671\\Anaconda3\\envs\\stmfnet\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3066\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3068\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3069\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3070\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "args = trainArgs()\n",
    "import losses\n",
    "loss = losses.DistillationLoss(args)\n",
    "\n",
    "start_epoch = 0\n",
    "if args.load is not None:\n",
    "    checkpoint = torch.load(args.load)\n",
    "    student.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    start_epoch = checkpoint[\"epoch\"]\n",
    "\n",
    "my_trainer = Distiller(args, train_loader, valid_loader, student, loss, start_epoch)\n",
    "\n",
    "now = datetime.datetime.now().strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "with open(join(args.out_dir, \"config.txt\"), \"a\") as f:\n",
    "    f.write(now + \"\\n\\n\")\n",
    "    for arg in vars(args):\n",
    "        f.write(\"{}: {}\\n\".format(arg, getattr(args, arg)))\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "while not my_trainer.terminate():\n",
    "    my_trainer.train()\n",
    "    my_trainer.save_checkpoint()\n",
    "    my_trainer.validate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loss(\n",
       "  (loss_module): ModuleList(\n",
       "    (0): LaplacianLoss(\n",
       "      (criterion): L1Loss()\n",
       "      (lap): LaplacianPyramid(\n",
       "        (gaussian_conv): GaussianConv()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on dataset:  Ucf101_quintuplet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wg19671\\Anaconda3\\envs\\stmfnet\\lib\\site-packages\\torchvision\\utils.py:63: UserWarning: The parameter 'range' is deprecated since 0.12 and will be removed in 0.14. Please use 'value_range' instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0               -- {'PSNR': 26.01, 'SSIM': 0.84}\n",
      "1               -- {'PSNR': 41.335, 'SSIM': 0.997}\n",
      "10              -- {'PSNR': 33.793, 'SSIM': 0.991}\n",
      "11              -- {'PSNR': 31.247, 'SSIM': 0.973}\n",
      "12              -- {'PSNR': 34.663, 'SSIM': 0.985}\n",
      "13              -- {'PSNR': 35.933, 'SSIM': 0.988}\n",
      "14              -- {'PSNR': 29.769, 'SSIM': 0.955}\n",
      "15              -- {'PSNR': 29.514, 'SSIM': 0.974}\n",
      "16              -- {'PSNR': 33.739, 'SSIM': 0.99}\n",
      "17              -- {'PSNR': 25.378, 'SSIM': 0.946}\n",
      "18              -- {'PSNR': 33.509, 'SSIM': 0.993}\n",
      "19              -- {'PSNR': 38.037, 'SSIM': 0.994}\n",
      "2               -- {'PSNR': 39.235, 'SSIM': 0.996}\n",
      "20              -- {'PSNR': 37.453, 'SSIM': 0.992}\n",
      "21              -- {'PSNR': 31.144, 'SSIM': 0.983}\n",
      "22              -- {'PSNR': 35.097, 'SSIM': 0.985}\n",
      "23              -- {'PSNR': 28.47, 'SSIM': 0.971}\n",
      "24              -- {'PSNR': 40.438, 'SSIM': 0.998}\n",
      "25              -- {'PSNR': 29.044, 'SSIM': 0.943}\n",
      "26              -- {'PSNR': 38.616, 'SSIM': 0.995}\n",
      "27              -- {'PSNR': 33.105, 'SSIM': 0.964}\n",
      "28              -- {'PSNR': 28.439, 'SSIM': 0.955}\n",
      "29              -- {'PSNR': 35.581, 'SSIM': 0.988}\n",
      "3               -- {'PSNR': 30.756, 'SSIM': 0.983}\n",
      "30              -- {'PSNR': 32.0, 'SSIM': 0.987}\n",
      "31              -- {'PSNR': 33.768, 'SSIM': 0.976}\n",
      "32              -- {'PSNR': 25.767, 'SSIM': 0.964}\n",
      "33              -- {'PSNR': 31.532, 'SSIM': 0.975}\n",
      "34              -- {'PSNR': 22.894, 'SSIM': 0.806}\n",
      "35              -- {'PSNR': 28.388, 'SSIM': 0.952}\n",
      "36              -- {'PSNR': 39.686, 'SSIM': 0.991}\n",
      "37              -- {'PSNR': 40.852, 'SSIM': 0.996}\n",
      "38              -- {'PSNR': 26.081, 'SSIM': 0.948}\n",
      "39              -- {'PSNR': 35.554, 'SSIM': 0.983}\n",
      "4               -- {'PSNR': 32.206, 'SSIM': 0.99}\n",
      "40              -- {'PSNR': 30.106, 'SSIM': 0.974}\n",
      "41              -- {'PSNR': 25.518, 'SSIM': 0.934}\n",
      "42              -- {'PSNR': 36.024, 'SSIM': 0.989}\n",
      "43              -- {'PSNR': 32.262, 'SSIM': 0.988}\n",
      "44              -- {'PSNR': 32.406, 'SSIM': 0.975}\n",
      "45              -- {'PSNR': 32.752, 'SSIM': 0.962}\n",
      "46              -- {'PSNR': 32.552, 'SSIM': 0.929}\n",
      "47              -- {'PSNR': 24.726, 'SSIM': 0.899}\n",
      "48              -- {'PSNR': 22.487, 'SSIM': 0.918}\n",
      "49              -- {'PSNR': 27.367, 'SSIM': 0.939}\n",
      "5               -- {'PSNR': 37.57, 'SSIM': 0.993}\n",
      "50              -- {'PSNR': 37.678, 'SSIM': 0.989}\n",
      "51              -- {'PSNR': 37.815, 'SSIM': 0.987}\n",
      "52              -- {'PSNR': 35.305, 'SSIM': 0.987}\n",
      "53              -- {'PSNR': 40.314, 'SSIM': 0.998}\n",
      "54              -- {'PSNR': 26.763, 'SSIM': 0.948}\n",
      "55              -- {'PSNR': 26.125, 'SSIM': 0.862}\n",
      "56              -- {'PSNR': 31.458, 'SSIM': 0.989}\n",
      "57              -- {'PSNR': 34.214, 'SSIM': 0.98}\n",
      "58              -- {'PSNR': 29.747, 'SSIM': 0.975}\n",
      "59              -- {'PSNR': 29.135, 'SSIM': 0.943}\n",
      "6               -- {'PSNR': 24.464, 'SSIM': 0.917}\n",
      "60              -- {'PSNR': 35.021, 'SSIM': 0.978}\n",
      "61              -- {'PSNR': 44.401, 'SSIM': 0.997}\n",
      "62              -- {'PSNR': 34.073, 'SSIM': 0.994}\n",
      "63              -- {'PSNR': 33.878, 'SSIM': 0.975}\n",
      "64              -- {'PSNR': 30.052, 'SSIM': 0.954}\n",
      "65              -- {'PSNR': 35.652, 'SSIM': 0.986}\n",
      "66              -- {'PSNR': 29.259, 'SSIM': 0.935}\n",
      "67              -- {'PSNR': 32.915, 'SSIM': 0.981}\n",
      "68              -- {'PSNR': 33.073, 'SSIM': 0.985}\n",
      "69              -- {'PSNR': 34.072, 'SSIM': 0.981}\n",
      "7               -- {'PSNR': 30.183, 'SSIM': 0.961}\n",
      "70              -- {'PSNR': 29.219, 'SSIM': 0.901}\n",
      "71              -- {'PSNR': 36.09, 'SSIM': 0.991}\n",
      "72              -- {'PSNR': 33.868, 'SSIM': 0.992}\n",
      "73              -- {'PSNR': 45.347, 'SSIM': 0.999}\n",
      "74              -- {'PSNR': 40.76, 'SSIM': 0.987}\n",
      "75              -- {'PSNR': 31.803, 'SSIM': 0.97}\n",
      "76              -- {'PSNR': 34.674, 'SSIM': 0.986}\n",
      "77              -- {'PSNR': 43.824, 'SSIM': 0.999}\n",
      "78              -- {'PSNR': 35.802, 'SSIM': 0.992}\n",
      "79              -- {'PSNR': 38.975, 'SSIM': 0.996}\n",
      "8               -- {'PSNR': 29.617, 'SSIM': 0.971}\n",
      "80              -- {'PSNR': 21.891, 'SSIM': 0.85}\n",
      "81              -- {'PSNR': 31.859, 'SSIM': 0.946}\n",
      "82              -- {'PSNR': 32.231, 'SSIM': 0.968}\n",
      "83              -- {'PSNR': 35.778, 'SSIM': 0.984}\n",
      "84              -- {'PSNR': 37.567, 'SSIM': 0.992}\n",
      "85              -- {'PSNR': 38.701, 'SSIM': 0.985}\n",
      "86              -- {'PSNR': 32.83, 'SSIM': 0.988}\n",
      "87              -- {'PSNR': 35.204, 'SSIM': 0.989}\n",
      "88              -- {'PSNR': 36.949, 'SSIM': 0.992}\n",
      "89              -- {'PSNR': 31.741, 'SSIM': 0.967}\n",
      "9               -- {'PSNR': 30.846, 'SSIM': 0.983}\n",
      "90              -- {'PSNR': 31.49, 'SSIM': 0.968}\n",
      "91              -- {'PSNR': 37.738, 'SSIM': 0.99}\n",
      "92              -- {'PSNR': 40.29, 'SSIM': 0.988}\n",
      "93              -- {'PSNR': 40.657, 'SSIM': 0.992}\n",
      "94              -- {'PSNR': 34.725, 'SSIM': 0.952}\n",
      "95              -- {'PSNR': 39.789, 'SSIM': 0.995}\n",
      "96              -- {'PSNR': 26.278, 'SSIM': 0.958}\n",
      "97              -- {'PSNR': 35.03, 'SSIM': 0.993}\n",
      "98              -- {'PSNR': 40.815, 'SSIM': 0.991}\n",
      "99              -- {'PSNR': 37.551, 'SSIM': 0.991}\n",
      "Average         -- {'PSNR': 33.383, 'SSIM': 0.97}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "args=testArgs()\n",
    "print(\"Testing on dataset: \", args.dataset)\n",
    "test_dir = os.path.join(args.out_dir, args.dataset)\n",
    "if args.dataset.split(\"_\")[0] in [\"VFITex\", \"Ucf101\", \"Davis90\"]:\n",
    "    db_folder = args.dataset.split(\"_\")[0].lower()\n",
    "else:\n",
    "    db_folder = args.dataset.lower()\n",
    "test_db = getattr(testsets, args.dataset)(os.path.join(args.data_dir, db_folder))\n",
    "if not os.path.exists(test_dir):\n",
    "    os.mkdir(test_dir)\n",
    "\n",
    "test_db.eval(teacher, metrics=args.metrics, output_dir=test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from os.path import join, exists\n",
    "import utility\n",
    "from torchvision.utils import save_image as imwrite\n",
    "\n",
    "db_dir = './tests/'\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "im_list = os.listdir(db_dir)\n",
    "\n",
    "input1_list = []\n",
    "input3_list = []\n",
    "input5_list = []\n",
    "input7_list = []\n",
    "gt_list = []\n",
    "for item in im_list:\n",
    "    input1_list.append(\n",
    "        transform(Image.open(join(db_dir, item, \"frame0.png\")))\n",
    "        .cuda()\n",
    "        .unsqueeze(0)\n",
    "    )\n",
    "    input3_list.append(\n",
    "        transform(Image.open(join(db_dir, item, \"frame1.png\")))\n",
    "        .cuda()\n",
    "        .unsqueeze(0)\n",
    "    )\n",
    "    input5_list.append(\n",
    "        transform(Image.open(join(db_dir, item, \"frame2.png\")))\n",
    "        .cuda()\n",
    "        .unsqueeze(0)\n",
    "    )\n",
    "    input7_list.append(\n",
    "        transform(Image.open(join(db_dir, item, \"frame3.png\")))\n",
    "        .cuda()\n",
    "        .unsqueeze(0)\n",
    "    )\n",
    "    gt_list.append(\n",
    "        transform(Image.open(join(db_dir, item, \"framet.png\")))\n",
    "        .cuda()\n",
    "        .unsqueeze(0)\n",
    "    )\n",
    "\n",
    "# def eval(model, , output_dir=None, output_name=\"output.png\"):\n",
    "# model.eval()\n",
    "\n",
    "output_dir = \"./tests/\"\n",
    "output_name = \"output.png\"\n",
    "\n",
    "\n",
    "# results_dict = {k: [] for k in metrics}\n",
    "\n",
    "# logfile = open(join(output_dir, \"results.txt\"), \"a\")\n",
    "\n",
    "for idx in range(len(im_list)):\n",
    "    if not exists(join(output_dir, im_list[idx])):\n",
    "        os.makedirs(join(output_dir, im_list[idx]))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model(\n",
    "            input1_list[idx],\n",
    "            input3_list[idx],\n",
    "            input5_list[idx],\n",
    "            input7_list[idx],\n",
    "        )\n",
    "    gt = gt_list[idx]\n",
    "\n",
    "\n",
    "    imwrite(out, join(output_dir, im_list[idx], output_name), range=(0, 1))\n",
    "\n",
    "#     msg = (\n",
    "#         \"{:<15s} -- {}\".format(\n",
    "#             im_list[idx],\n",
    "#             {k: round(results_dict[k][-1], 3) for k in metrics},\n",
    "#         )\n",
    "#         + \"\\n\"\n",
    "#     )\n",
    "#     print(msg, end=\"\")\n",
    "#     logfile.write(msg)\n",
    "\n",
    "# msg = (\n",
    "#     \"{:<15s} -- {}\".format(\n",
    "#         \"Average\", {k: round(np.mean(results_dict[k]), 3) for k in metrics}\n",
    "#     )\n",
    "#     + \"\\n\\n\"\n",
    "# )\n",
    "# print(msg, end=\"\")\n",
    "# logfile.write(msg)\n",
    "# logfile.close()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('stmfnet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5be8633809c4d4a6fd98bbeceba3cc69f691646712380d18efdcb68d5866f12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
