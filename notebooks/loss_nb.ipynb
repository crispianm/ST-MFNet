{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import utility\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from importlib import import_module\n",
    "import datetime\n",
    "import torch.optim as optim\n",
    "from models import *\n",
    "import models\n",
    "from data.datasets import *\n",
    "from trainers.distiller import Distiller\n",
    "import losses\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainArgs:\n",
    "    gpu_id = 0\n",
    "    net = 'STMFNet'\n",
    "    data_dir = 'D:/stmfnet_data'\n",
    "    out_dir = './train_results'\n",
    "    load = None\n",
    "    epochs = 70\n",
    "    batch_size = 2\n",
    "    loss = \"1*Lap\"\n",
    "    patch_size = 256\n",
    "    lr = 0.001\n",
    "    lr_decay = 20\n",
    "    decay_type = 'step'\n",
    "    gamma = 0.5\n",
    "    patience = None\n",
    "    optimizer = 'ADAMax'\n",
    "    weight_decay = 0\n",
    "    featc = [32, 64, 96, 128]\n",
    "    featnet = 'UMultiScaleResNext'\n",
    "    featnorm = 'batch'\n",
    "    kernel_size = 5\n",
    "    dilation = 1\n",
    "    finetune_pwc = False\n",
    "    temp = 10\n",
    "    alpha = 0.3\n",
    "    distill_loss_fn = 'KLDivLoss'\n",
    "\n",
    "args=trainArgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.datasets import *\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "torch.cuda.set_device(args.gpu_id)\n",
    "\n",
    "# training sets\n",
    "vimeo90k_train = Vimeo90k_quintuplet(\n",
    "    join(args.data_dir, \"vimeo_septuplet\"),\n",
    "    train=True,\n",
    "    crop_sz=(args.patch_size, args.patch_size),\n",
    ")\n",
    "bvidvc_train = BVIDVC_quintuplet(\n",
    "    join(args.data_dir, \"bvidvc\"), crop_sz=(args.patch_size, args.patch_size)\n",
    ")\n",
    "\n",
    "# validation set\n",
    "vimeo90k_valid = Vimeo90k_quintuplet(\n",
    "    join(args.data_dir, \"vimeo_septuplet\"),\n",
    "    train=False,\n",
    "    crop_sz=(args.patch_size, args.patch_size),\n",
    "    augment_s=False,\n",
    "    augment_t=False,\n",
    ")\n",
    "\n",
    "datasets_train = [bvidvc_train]\n",
    "train_sampler = Sampler(datasets_train, iter=True)\n",
    "\n",
    "# data loaders\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_sampler, batch_size=args.batch_size, shuffle=True, num_workers=0\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    dataset=vimeo90k_valid, batch_size=args.batch_size, num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "\n",
    "\n",
    "torch.cuda.set_device(args.gpu_id)\n",
    "\n",
    "if not os.path.exists(args.out_dir):\n",
    "    os.mkdir(args.out_dir)\n",
    "\n",
    "def to_device(data, device):\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "# def load_model(filepath):\n",
    "\n",
    "#     checkpoint = torch.load(filepath)\n",
    "#     model = STMFNet(args).cuda()\n",
    "#     model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# model = load_model(\"./models/stmfnet.pth\")\n",
    "\n",
    "teacher = to_device(STMFNet(args), device)\n",
    "teacher.to(device)\n",
    "checkpoint = torch.load('./models/stmfnet.pth')\n",
    "teacher.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define student model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1 = to_device(student_STMFNet(args), device)\n",
    "st1.to(device)\n",
    "checkpoint1 = torch.load('./train_results/checkpoint/model_epoch028.pth')\n",
    "st1.load_state_dict(checkpoint1['state_dict'])\n",
    "\n",
    "# st2 = to_device(student_STMFNet(args), device)\n",
    "# st2.to(device)\n",
    "# checkpoint2 = torch.load('./train_results/checkpoint/model_epoch005.pth')\n",
    "# st2.load_state_dict(checkpoint2['state_dict'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getmax():\n",
    "    nums = []\n",
    "    for file in os.listdir('./train_results/checkpoint'):\n",
    "        if file.endswith('.pth'):\n",
    "            nums.append(int(file.split('_epoch')[-1].split('.')[0]))\n",
    "    return max(nums)\n",
    "\n",
    "getmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it_1 = next(iter(train_loader))\n",
    "\n",
    "# for batch_idx, (frame1, frame3, frame4, frame5, frame7) in enumerate(train_loader, 1):\n",
    "# optimizer.zero_grad()\n",
    "\n",
    "frame1 = it_1[0].cuda()\n",
    "frame3 = it_1[1].cuda()\n",
    "frame4 = it_1[2].cuda()\n",
    "frame5 = it_1[3].cuda()\n",
    "frame7 = it_1[4].cuda()\n",
    "\n",
    "import losses\n",
    "output1 = st1(frame1, frame3, frame5, frame7)\n",
    "# output2 = st2(frame1, frame3, frame5, frame7)\n",
    "targets = teacher(frame1, frame3, frame5, frame7)\n",
    "\n",
    "fig, ax = plt.subplot_mosaic([\n",
    "    ['student1','teacher', 'ground truth'],\n",
    "], figsize=(24, 10))\n",
    "fig.patch.set_facecolor('xkcd:white')\n",
    "ax['student1'].imshow(output1['frame1'][0,:,:,:].permute(1, 2, 0).cpu().detach().numpy())\n",
    "ax['student1'].set_title('Distilled Student')\n",
    "ax['student1'].axis('off')\n",
    "\n",
    "# ax['student2'].imshow(output1['frame1'][0,:,:,:].permute(1, 2, 0).cpu().detach().numpy())\n",
    "# ax['student2'].set_title('Trained Student')\n",
    "# ax['student2'].axis('off')\n",
    "\n",
    "ax['teacher'].imshow(targets['frame1'][0,:,:,:].permute(1, 2, 0).cpu().detach().numpy())\n",
    "ax['teacher'].set_title('teacher')\n",
    "ax['teacher'].axis('off')\n",
    "\n",
    "ax['ground truth'].imshow(frame4[0,:,:,:].permute(1, 2, 0).cpu().detach().numpy())\n",
    "ax['ground truth'].set_title('ground truth')\n",
    "ax['ground truth'].axis('off')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from data import testsets\n",
    "\n",
    "# class testArgs:\n",
    "#     gpu_id = 0\n",
    "#     net = 'STMFNet'\n",
    "#     dataset = 'Ucf101_quintuplet'\n",
    "#     metrics = ['PSNR', 'SSIM']\n",
    "#     checkpoint = './train_results/checkpoint/model_epoch008.pth'\n",
    "#     # checkpoint = './models/stmfnet.pth'\n",
    "#     data_dir = 'D:/stmfnet_data'\n",
    "#     out_dir = './tests/results'\n",
    "#     featc = [64, 128, 256, 512]\n",
    "#     featnet = 'UMultiScaleResNext'\n",
    "#     featnorm = 'batch'\n",
    "#     kernel_size = 5\n",
    "#     dilation = 1\n",
    "#     finetune_pwc = False\n",
    "\n",
    "# args = testArgs()\n",
    "\n",
    "\n",
    "# densities = {}\n",
    "# for i in range(getmax()):\n",
    "#     model = to_device(STMFNet(args), device)\n",
    "#     model.to(device)\n",
    "#     model_name = \"model_epoch\" + str(i+1).zfill(3)\n",
    "#     model_path = \"./train_results/checkpoint/\" + model_name + \".pth\"\n",
    "#     checkpoint = torch.load(model_path)\n",
    "#     model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "#     weights = [w for name, w in model.named_parameters() if \"weight\" in name]\n",
    "#     num_features = sum([w.numel() for w in weights])\n",
    "#     density = sum([torch.sum(w != 0).item() for w in weights]) / num_features\n",
    "#     print(density)\n",
    "#     densities[str(i+1).zfill(3)] = density\n",
    "\n",
    "#     # test_dir = os.path.join(args.out_dir, args.dataset)\n",
    "#     # if args.dataset.split(\"_\")[0] in [\"VFITex\", \"Ucf101\", \"Davis90\"]:\n",
    "#     #     db_folder = args.dataset.split(\"_\")[0].lower()\n",
    "#     # else:\n",
    "#     #     db_folder = args.dataset.lower()\n",
    "#     # test_db = getattr(testsets, args.dataset)(os.path.join(args.data_dir, db_folder))\n",
    "#     # if not os.path.exists(test_dir):\n",
    "#     #     os.mkdir(test_dir)\n",
    "\n",
    "#     # test_db.eval(model, metrics=args.metrics, output_dir=test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = to_device(STMFNet(args), device)\n",
    "# model.to(device)\n",
    "# model_path = \"./train_results/checkpoint/model_epoch008.pth\"\n",
    "# checkpoint = torch.load(model_path)\n",
    "\n",
    "# model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "# x = summary(model, [(2, 3, 256, 256), (2, 3, 256, 256), (2, 3, 256, 256), (2, 3, 256, 256)])\n",
    "\n",
    "# with open('./summaries/'+model_name+'.txt', 'w') as f:\n",
    "#     f.write(str(x))\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = frame4\n",
    "# student_output = st2(frame1, frame3, frame5, frame7)\n",
    "# teacher_output = teacher(frame1, frame3, frame5, frame7)\n",
    "\n",
    "student_output = output1\n",
    "teacher_output = targets\n",
    "\n",
    "lap_module = import_module('losses.laplacianpyramid')\n",
    "charb_module = import_module('losses.charbonnier')\n",
    "\n",
    "student_loss_function = getattr(lap_module, 'LaplacianLoss')()\n",
    "distill_loss_function = getattr(lap_module, 'LaplacianLoss')()\n",
    "distill_loss_function = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "\n",
    "student_loss_function.to('cuda')\n",
    "distill_loss_function.to('cuda')\n",
    "\n",
    "def distillation_loss(student_pred, teacher_pred, distill_loss_fn, temperature=10):\n",
    "    soft_pred = softmax(student_pred / temperature)\n",
    "    soft_labels = softmax(teacher_pred / temperature)\n",
    "    loss = distill_loss_fn(soft_pred, soft_labels) * temperature**2\n",
    "    return loss\n",
    "\n",
    "softmax = nn.Softmax(dim=0)\n",
    "\n",
    "student_loss = student_loss_function(\n",
    "    gt,\n",
    "    softmax(student_output['frame1'])\n",
    ")\n",
    "print('student_loss: ', student_loss)\n",
    "distill_loss = distillation_loss(\n",
    "    student_pred = torch.reshape(student_output['frame1'], (1, -1)),\n",
    "    teacher_pred = torch.reshape(teacher_output['frame1'], (1, -1)),\n",
    "    distill_loss_fn = distill_loss_function,\n",
    "    temperature=10\n",
    ")\n",
    "print('distill_loss: ', distill_loss)\n",
    "effective_loss = 0.1 * student_loss + \\\n",
    "    (1 - 0.1) * distill_loss\n",
    "print('effective_loss: ', effective_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class LinearEmbedding(nn.Module):\n",
    "    def __init__(self, base, output_size=512, embedding_size=128, normalize=True):\n",
    "        super(LinearEmbedding, self).__init__()\n",
    "        self.base = base\n",
    "        self.linear = nn.Linear(output_size, embedding_size)\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def forward(self, x, get_ha=False):\n",
    "        if get_ha:\n",
    "            b1, b2, b3, b4, pool = self.base(x, True)\n",
    "        else:\n",
    "            pool = self.base(x)\n",
    "\n",
    "        pool = pool.view(x.size(0), -1)\n",
    "        embedding = self.linear(pool)\n",
    "\n",
    "        if self.normalize:\n",
    "            embedding = F.normalize(embedding, p=2, dim=1)\n",
    "\n",
    "        if get_ha:\n",
    "            return b1, b2, b3, b4, pool, embedding\n",
    "\n",
    "        return embedding\n",
    "\n",
    "teach = LinearEmbedding(teacher)\n",
    "stud = LinearEmbedding(st1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rkd import RKD\n",
    "\n",
    "def get_embedding(model, device, image, out_features, normalize=True):\n",
    "    linear =  nn.Linear(out_features, 128)\n",
    "    linear.to(device)\n",
    "    pool = image['frame1'].view(image['frame1'].size(0), -1)\n",
    "    embedding = linear(pool)\n",
    "    if normalize:\n",
    "        embedding = F.normalize(embedding, p=2, dim=1)\n",
    "\n",
    "    return embedding\n",
    "t_e = get_embedding(teach, device, teacher_output, 196608, True)\n",
    "e = get_embedding(stud, device, student_output, 196608, True)\n",
    "\n",
    "losss = RKD(1,2)\n",
    "losss.to(device)\n",
    "losss(t_e, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('stmfnet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5be8633809c4d4a6fd98bbeceba3cc69f691646712380d18efdcb68d5866f12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
